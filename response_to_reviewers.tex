\section*{Response to Reviewers}

\subsection*{Reviewer \#1}

\paragraph{Comment 3.1 (GDP per-capita decomposition request).}
We implemented the requested decomposition by extending the Canterbury SCM to estimate three outcomes under the \emph{same} donor pool and pre-treatment setup: (i) GDP per capita, (ii) total regional GDP (level), and (iii) total population.

We added two new figures and accompanying text to the manuscript (Section~4, Results). Figure~\ref{fig:nz_decomposition_paths} shows the treated vs.\ synthetic paths for total GDP and population; Figure~\ref{fig:nz_decomposition_gaps} displays the corresponding gaps in percentage terms. The revised text reports: by 2016, the GDP-per-capita gap is 12.7\%, the total-GDP gap is 5.9\%, and the population gap is $-3.6$\%. Averaging over 2011--2022, the gaps are 6.8\% (GDP per capita), 5.0\% (total GDP), and $-3.6$\% (population).

\paragraph{Interpretation}
Yes, Canterbury's per-capita gap survives the decomposition. The positive post-quake GDP-per-capita divergence is not driven by denominator mechanics alone: total GDP itself rises above synthetic, while population remains below synthetic. Hence, the per-capita effect reflects the combined contribution of a stronger numerator and a smaller denominator relative to the counterfactual.

\paragraph{Comment 3.2 (uniform confidence sets and timing sensitivity).}
\textit{``Please move beyond placebo spaghetti plots and provide uniform confidence sets over the post-treatment path, including timing/fitting sensitivity checks.''}

\paragraph{Response.}
Implemented. We added a dedicated module (\texttt{src/uniform\_confidence\_analysis.py}) that computes placebo-based \emph{uniform confidence sets} for SCM treatment effects over the full post-treatment horizon (simultaneous, not pointwise). The procedure studentizes each placebo path by pre-treatment RMSPE and uses the placebo sup-norm distribution to obtain a finite-sample critical value, following \textcite{firpo2018synthetic}. Outputs are exported as reproducible artifacts (\texttt{article\_assets/scm\_uniform\_confidence\_sets.csv}, \texttt{article\_assets/scm\_uniform\_confidence\_summary.csv}) and visualized in new manuscript figures.

We also implemented both requested sensitivity checks:
\begin{itemize}
  \item \textbf{Chile (Maule):} alternative placebo pre-fit filters (2$\times$, 5$\times$, 10$\times$ treated pre-RMSPE).
  \item \textbf{New~Zealand (Canterbury):} treatment-start definitions of 2010 vs.\ 2011.
\end{itemize}

Main conclusions are stable: Maule's uniform set includes zero throughout the post period, while Canterbury shows non-zero positive years concentrated in early-to-mid rebuild years, with later attenuation and re-convergence. We retain the in-time placebo diagnostics as a complementary falsification check and report both tools in the revised robustness section.

\paragraph{Comment 3.3 (SDID and bias-corrected SCM robustness).}
\textit{``Given the long post-treatment window, please implement SDID and a bias-corrected/penalized SCM (especially for Maule) to test robustness to inexact matching.''}

\paragraph{Response.}
Implemented. We added a new robustness module (\texttt{src/sdid\_bias\_corrected\_analysis.py}) that estimates:
\begin{enumerate}
  \item SDID for both Canterbury and Maule, and
  \item penalized (bias-corrected) SCM following the Abadie--L'Hour framework (reported for both countries; requested case Maule included).
\end{enumerate}

The revised manuscript reports these estimates in a new robustness table and figure (Table~\ref{tab:sdid_penalized}, Figure~\ref{fig:sdid_penalized_gaps}). Numerically:
\begin{itemize}
  \item \textbf{Canterbury}: baseline SCM average post-gap (2011--2019) is \(+7.8\%\); SDID is \(+7.8\%\); penalized SCM is \(+6.5\%\).
  \item \textbf{Maule}: baseline SCM average post-gap (2010--2019) is \(-1.7\%\); SDID is \(-5.1\%\); penalized SCM is \(-1.5\%\).
\end{itemize}

Hence, Canterbury's overshoot persists when optimizing both unit and time weights (SDID), while Maule remains non-positive under all alternative estimators. This directly addresses concerns about long-window robustness and edge-of-convex-hull matching for Maule.

\paragraph{Minor comment (data-quality corroboration via night-time lights).}
\textit{``Corroborate regional GDP findings with an objective proxy such as NTL intensity.''}

\paragraph{Response.}
Implemented. We added a new reproducible module, \texttt{src/nighttime\_lights\_validation.py}, that builds annual regional NTL series and runs parallel SCM validation for Chile (Maule) and New Zealand (Canterbury). The script:
\begin{enumerate}
  \item aggregates a harmonized DMSP-OLS/VIIRS annual product to regional boundaries used in our SCM design;
  \item re-estimates SCM on NTL outcomes for both treated regions (same treatment timing logic); and
  \item exports product-sensitivity and spatial-sensitivity checks (urban-core mask in Maule; Christchurch buffers for Canterbury).
\end{enumerate}

New outputs are exported to \texttt{article\_assets/} (including \texttt{ntl\_validation\_paths\_gaps.png}, \texttt{ntl\_sensor\_processing\_robustness.png}, \texttt{ntl\_spatial\_sensitivity.png}, and summary CSV tables).

\paragraph{Interpretation}
For Canterbury, NTL confirms the GDP-based result: positive post-treatment divergence (about +10.0\% in 2016; average post-gap about +7.8\%). For Maule, NTL diverges from the GDP-null result (positive NTL post-gap). We now state this explicitly in the manuscript and discuss it as evidence that remote-sensing proxies can capture broader spatial re-lighting and infrastructure restoration dynamics that do not map one-to-one to measured value-added in regional GDP accounts. Product and spatial sensitivity checks preserve this qualitative pattern.

\section*{Reproducibility note}

All figures and tables cited above appear in the revised manuscript. The analysis code is available in the supplementary repository for verification.
